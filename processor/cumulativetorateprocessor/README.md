# Cumulative to Rate Processor

<!-- status autogenerated section -->
| Status        |           |
| ------------- |-----------|
| Stability     | [alpha]: metrics   |
| Distributions | [contrib] |
| Issues        | [![Open issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aopen%20label%3Aprocessor%2Fcumulativetorate%20&label=open&color=orange&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aopen+is%3Aissue+label%3Aprocessor%2Fcumulativetorate) [![Closed issues](https://img.shields.io/github/issues-search/open-telemetry/opentelemetry-collector-contrib?query=is%3Aissue%20is%3Aclosed%20label%3Aprocessor%2Fcumulativetorate%20&label=closed&color=blue&logo=opentelemetry)](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues?q=is%3Aclosed+is%3Aissue+label%3Aprocessor%2Fcumulativetorate) |

[alpha]: https://github.com/open-telemetry/opentelemetry-collector#alpha
[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib
<!-- end autogenerated section -->

## Description

The Cumulative to Rate processor converts cumulative sum metrics to rate metrics (per-second rates). This processor is specifically designed to handle monotonic cumulative counters and convert them into gauge metrics representing the rate of change.

The processor maintains state between processing cycles to calculate rates by comparing current values with previously seen values. It has strict filtering criteria and only processes metrics that meet specific requirements.

## Supported pipeline types

| Pipeline | Supported |
| -------- | --------- |
| metrics  | ✓         |

## Processing Criteria

The processor will **ONLY** process metrics that meet **ALL** of the following criteria:

### ✅ Required Metric Properties
1. **Metric Type**: Must be `Sum` type
2. **Aggregation Temporality**: Must be `Cumulative` 
3. **Monotonic**: Must be `true` (monotonic counters only)
4. **Data Points**: Must have at least one data point with a valid timestamp

### ✅ Filter Matching (if configured)
- Must match `include` patterns (if specified)
- Must NOT match `exclude` patterns (if specified)

### ❌ Metrics That Are Skipped
- **Non-Sum metrics**: Gauge, Histogram, Summary, ExponentialHistogram
- **Delta Sum metrics**: `AggregationTemporalityDelta` 
- **Non-Monotonic Sums**: `IsMonotonic() == false`
- **Empty metrics**: No data points
- **Invalid timestamps**: Missing or zero timestamps
- **Filter mismatches**: Don't match include/exclude patterns

## How it works

1. **Metric Filtering**: Only cumulative, monotonic sum metrics are processed
2. **State Management**: Maintains previous value and timestamp for each unique metric identity
3. **Identity Generation**: Creates unique keys based on metric name, resource attributes, scope attributes, and data point attributes
4. **Rate Calculation**: Calculates rate as `(current_value - previous_value) / time_delta_seconds`
5. **Metric Conversion**: Converts sum to gauge with the calculated rate value
6. **State Updates**: Stores current values for next calculation cycle
7. **Cleanup**: Periodically removes old state entries based on TTL

### Metric Identity

Each metric's state is tracked using a unique identity composed of:
- Metric name
- Resource attributes (serialized)
- Scope name and version
- Data point attributes (serialized)

This ensures that metrics with the same name but different attribute sets are tracked separately.

## Configuration

```yaml
processors:
  cumulativetorate:
    # Optional: List of metric name patterns to include (supports wildcards)
    include:
      - "system.cpu.*"
      - "process.memory.usage"
    
    # Optional: List of metric name patterns to exclude (supports wildcards)  
    exclude:
      - "system.network.dropped"
      - "*.debug.*"
    
    # Optional: Time-to-live for metric state entries (default: 5m)
    # Helps prevent memory leaks by cleaning up old state
    state_ttl: 5m
```